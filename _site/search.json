[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex041/Hands-on_Ex041.html",
    "href": "Hands-on_Ex/Hands-on_Ex041/Hands-on_Ex041.html",
    "title": "Hands-on Exercise 4.1",
    "section": "",
    "text": "ggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse, rstantools, PMCMRplus)\n\n\n\n\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 <- exam %>% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\n\n\n\n\n\n\n\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n\n\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   <dbl> <chr>    <dbl>     <dbl>     <dbl>    <dbl>  <dbl>         <dbl>  <dbl>\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period <dbl>, HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\n\nIn the code chunk, check_normality() of performance package.\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n <- check_normality(model1)\nplot(check_n)\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h <- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this chapter, several ggplot2 extensions for creating more elegant and effective statistical graphics will be introduced. By the end of this exercise, I will be able to demonstrate the following:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2",
    "section": "Getting started",
    "text": "Getting started\n\nInstalling and loading the required libraries\nIn this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\n\n\nImporting data\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on Exercise 2",
    "section": "Beyond ggplot2 Annotation: ggrepel",
    "text": "Beyond ggplot2 Annotation: ggrepel\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right.\nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\nWorking with ggrepel\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: ggrepel: 317 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 2",
    "section": "Beyond ggplot2 Themes",
    "text": "Beyond ggplot2 Themes\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\nRefer to this link to learn more about ggplot2 Themes\n\nWorking with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nIn the example below, The Economist theme is used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\nWorking with hrbthems package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on Exercise 2",
    "section": "Beyond Single Graph",
    "text": "Beyond Single Graph\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, you will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics by using the code chunk below.\n\np1 <- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\np1\n\n\n\n\n\np2 <- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\np2\n\n\n\n\nLastly, we will draw a scatterplot for English score versus Maths score by as shown below\n\np3 <- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\np3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nCreating Composite Graphics: pathwork methods\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\nCombining two ggplot2 graphs\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\np1 + p2\n\n\n\n\n\n\nCombining three ggplot2 graphs\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“|” operator to stack two ggplot2 graphs,\n“/” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\n(p1 / p2) | p3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nTo learn more about, refer to Plot Assembly.\n\n\nCreating a composite figure with tag\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nCreating figure with insert\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np12 <- p1|p2\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nCreating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\npatchwork <- (p1 / p2) | p3\npatchwork & theme_economist()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex031/Hands-on_Ex031.html",
    "href": "Hands-on_Ex/Hands-on_Ex031/Hands-on_Ex031.html",
    "title": "Hands-on Exercise 3.1",
    "section": "",
    "text": "First, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex031/Hands-on_Ex031.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex031/Hands-on_Ex031.html#importing-data",
    "title": "Hands-on Exercise 3.1",
    "section": "Importing Data",
    "text": "Importing Data\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex031/Hands-on_Ex031.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex031/Hands-on_Ex031.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3.1",
    "section": "Interactive Data Visualisation - ggiraph methods",
    "text": "Interactive Data Visualisation - ggiraph methods\nggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\nTooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\n\nDisplaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip <- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\n\n\nDisplaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip <- function(y, ymax, accuracy = .01) {\n  mean <- scales::number(y, accuracy = accuracy)\n  sem <- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point <- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\nHover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\n\n\nStyling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\nCombining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\nClick effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\n\n\nCoordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 <- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex031/Hands-on_Ex031.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex031/Hands-on_Ex031.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3.1",
    "section": "Interactive Data Visualisation - plotly methods!",
    "text": "Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\nCreating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\nWorking with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\nCreating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\nCoordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nd <- highlight_key(exam_data)\np1 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\n\nVisit this link to learn more about crosstalk,"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex031/Hands-on_Ex031.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex031/Hands-on_Ex031.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3.1",
    "section": "Interactive Data Visualisation - crosstalk methods!",
    "text": "Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\nInteractive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\nLinked brushing: crosstalk method\nCode chunk below is used to implement the coordinated brushing shown above.\n\nd <- highlight_key(exam_data) \np <- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg <- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\nSetting the `off` event (i.e., 'plotly_deselect') to match the `on` event (i.e., 'plotly_selected'). You can change this default via the `highlight()` function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex042/Hands-on_Ex042.html",
    "href": "Hands-on_Ex/Hands-on_Ex042/Hands-on_Ex042.html",
    "title": "Hands-on Exercise 4.2",
    "section": "",
    "text": "A point estimate is a single number, such as a mean.\nUncertainty is expressed as standard error, confidence interval, or credible interval\nImportant:\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\npacman::p_load(tidyverse, plotly, crosstalk, DT, ggdist, gganimate, dplyr, ggplot2)\n\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\n\n\nThe code chunk below performs the followings:\n\ngroup the observation by RACE,\ncomputes the count of observations, mean, standard deviation and standard error of Maths by RACE, and\nsave the output as a tibble data table called my_sum.\n\n\nmy_sum <- exam %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nNext, the code chunk below will\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\n\n\n\nThe code chunk below is used to reveal the standard error of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by rac\")\n\n\n\n\n\n\n\n\n# calculate the upper and lower bounds of the confidence interval\nmy_sum <- my_sum %>%\n  mutate(lower = mean - 1.96 * se, upper = mean + 1.96 * se)\n\n# plot the data with error bars sorted by mean score\nggplot(my_sum, aes(x = mean, y = reorder(RACE, mean), xmin = lower, xmax = upper)) +\n  geom_errorbar(height = 0.2, colour = \"black\", alpha = 0.9, size = 0.5) +\n  geom_point(color = \"red\", size = 1.5, alpha = 1) +\n  ggtitle(\"95% Confidence Interval of Mean Math Score by Race\") +\n  xlab(\"Mean Math Score\") +\n  ylab(\"Race\") +\n  coord_flip() +\n  theme_bw()\n\n\n\n\n\n\n\n\n# calculate the upper and lower bounds of the confidence interval\nmy_sum <- my_sum %>%\n  mutate(lower = mean - 2.58 * se, upper = mean + 2.58 * se)\n\n# plot the data with error bars sorted by mean score\nggplot(my_sum, aes(x = mean, y = reorder(RACE, mean), xmin = lower, xmax = upper)) +\n  geom_errorbar(height = 0.2, colour = \"black\", alpha = 0.9, size = 0.5) +\n  geom_point(color = \"red\", size = 1.5, alpha = 1) +\n  ggtitle(\"95% Confidence Interval of Mean Math Score by Race\") +\n  xlab(\"Mean Math Score\") +\n  ylab(\"Race\") +\n  coord_flip() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +   #<<\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\nexam %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\n\nStep 1: Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex043/Hands-on_Ex043.html",
    "href": "Hands-on_Ex/Hands-on_Ex043/Hands-on_Ex043.html",
    "title": "Hands-on Exercise 4.3",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages.\n\n\n\n\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 <- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %>%\n  mutate_if(is.character, as.factor)\n\nRows: 267 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): City, District, Sub-district\ndbl (4): Sub-district ID, Positive, Recovered, Death\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is \"SR\".\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",     #<<\n  xrange = c(0, 6500),  #<<\n  yrange = c(0, 0.05)   #<<\n)\n\nWarning: The `xrange` argument deprecated; please use the `x_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\nWarning: The `yrange` argument deprecated; please use the `y_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above. + data_type argument is used to change from default \"SR\" to \"PR\" (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #<<\n  y_label = \"Cumulative Fatality Rate\"  #<<\n)\n\nWarning: The `xrange` argument deprecated; please use the `x_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\nWarning: The `yrange` argument deprecated; please use the `y_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.\n\n\n\n\n\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf <- covid19 %>%\n  mutate(rate = Death / Positive) %>%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %>%\n  filter(rate > 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean <- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq <- seq(1, max(df$Positive), 1)\nnumber.ll95 <- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 <- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 <- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 <- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI <- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np <- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\n\nWarning in geom_point(aes(label = `Sub-district`), alpha = 0.4): Ignoring\nunknown aesthetics: label\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\np\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly <- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse has been installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse) \n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Exercise 1",
    "section": "Essential Grammatical Elements in ggplot2: stat",
    "text": "Essential Grammatical Elements in ggplot2: stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\nWorking with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\nWorking with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\n\n\nWorking with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\nAdding a best fit curve on a scatterplot?\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Exercise 1",
    "section": "Essential Grammatical Elements in ggplot2: Facets",
    "text": "Essential Grammatical Elements in ggplot2: Facets\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\nWorking with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\nfacet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Exercise 1",
    "section": "Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "Essential Grammatical Elements in ggplot2: Coordinates\n\nWorking with Coordinate\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\nChanging the y- and x-axis range\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on Exercise 1",
    "section": "Essential Grammatical Elements in ggplot2: themes",
    "text": "Essential Grammatical Elements in ggplot2: themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\nWorking with theme\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex032/Hands-on_Ex032.html",
    "href": "Hands-on_Ex/Hands-on_Ex032/Hands-on_Ex032.html",
    "title": "Hands-on Exercise 3.2",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex032/Hands-on_Ex032.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex032/Hands-on_Ex032.html#getting-started",
    "title": "Hands-on Exercise 3.2",
    "section": "Getting Started",
    "text": "Getting Started\n\nLoading the R packages\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder, plotly, gganimate, tidyverse)\n\n\n\nImporting the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol <- c(\"Country\", \"Continent\")\nglobalPop <- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %>%\n  mutate_each_(funs(factor(.)), col) %>%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex032/Hands-on_Ex032.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex032/Hands-on_Ex032.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3.2",
    "section": "Animated Data Visualisation: gganimate methods",
    "text": "Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\nBuilding a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\nBuilding the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex032/Hands-on_Ex032.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex032/Hands-on_Ex032.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 3.2",
    "section": "Animated Data Visualisation: plotly",
    "text": "Animated Data Visualisation: plotly\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\nBuilding an animated bubble plot: ggplotly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n```{r}#| eval: false} gg <- ggplot(globalPop, aes(x = Old, y = Young, size = Population, colour = Country)) + geom_point(aes(size = Population, frame = Year), alpha = 0.7, show.legend = FALSE) + scale_colour_manual(values = country_colors) + scale_size(range = c(2, 12)) + labs(x = ‘% Aged’, y = ‘% Young’)\nggplotly(gg) ```\n\n\nBuilding an animated bubble plot: plot_ly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nbp <- globalPop %>%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent, \n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          )\nbp"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to the homepage for ISSS608 Visual Analytics and Applications! This course is designed to teach students how to create effective and engaging data visualizations using a variety of tools and techniques.\nOn this website, you will find all the coursework for the course, including lecture notes, assignments, and resources. We’ve also included some highlights of the course to give you a better idea of what you can expect to learn:\n\nDevelop skills in data analysis and visualization\nLearn to use cutting-edge tools and techniques to create compelling visualizations\nBuild a portfolio of visualizations to showcase your work to potential employers or collaborators\n\nWe’ve also included some of our best work from the course in the portfolio section. Feel free to take a look and get inspired!\nIf you have any questions or would like to connect with us, please use the contact form on our website. We would love to hear from you and help you get started on your journey to becoming a data visualization expert."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Unveiling Demographic and Financial Characteristics of City of Engagement: A Visual Analysis driven Study",
    "section": "",
    "text": "City of Engagement, with a total population of 50,000, is a small city located at Country of Nowhere. The city serves as a service centre of an agriculture region surrounding the city. The main agriculture of the region is fruit farms and vineyards. The local council of the city is in the process of preparing the Local Plan 2023. A sample survey of 1000 representative residents had been conducted to collect data related to their household demographic and spending patterns, among other things. The city aims to use the data to assist with their major community revitalization efforts, including how to allocate a very large city renewal grant they have recently received."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-cleaning",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-cleaning",
    "title": "Unveiling Demographic and Financial Characteristics of City of Engagement: A Visual Analysis driven Study",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nFirst, we will have to start with missing value check on both datasets.\n\n# Missing value check for financial_journal dataset\nmissing_values_fj <- sapply(Journal, function(x) sum(is.na(x)))\nprint(missing_values_fj)\n\nparticipantId     timestamp      category        amount \n            0             0             0             0 \n\n# Missing value check for participants dataset\nmissing_values_participants <- sapply(participants, function(x) sum(is.na(x)))\nprint(missing_values_participants)\n\n participantId  householdSize       haveKids            age educationLevel \n             0              0              0              0              0 \n interestGroup      joviality \n             0              0 \n\n\nSeems no missing value appears in the dataset, we them move on to the next part.\nNext part is checking for duplicate participant IDs: Ensure that each participant ID is unique and there are no duplicates. I use the duplicated() function to identify and remove any duplicate rows.\n\n# Checking for duplicate participant IDs\nduplicate_ids <- participants[duplicated(participants$participantId), \"participantId\"]\nif (length(duplicate_ids) > 0) {\n  print(paste(\"Duplicate participant IDs found:\", paste(duplicate_ids, collapse = \", \")))\n} else {\n  print(\"No duplicate participant IDs found.\")\n}\n\n[1] \"Duplicate participant IDs found: numeric(0)\"\n\n\nNext, I will perform categorical variable standardization, the levels of categorical variables like “educationLevel” or “interestGroup” might inconsistent capitalization or spelling, I decided to use functions like tolower() or recode() from the dplyr to standarde them for consistency and easier analysis.\n\nlibrary(dplyr)\n\n# Standardizing the educationLevel variable\nparticipants <- participants %>%\n  mutate(educationLevel = recode(educationLevel,\n                                 \"Low\" = \"Low\",\n                                 \"HighSchoolOrCollege\" = \"High School or College\",\n                                 \"Bachelors\" = \"Bachelors\",\n                                 \"Graduate\" = \"Graduate\"))\n\n# Standardizing the interestGroup variable\nparticipants <- participants %>%\n  mutate(interestGroup = recode(interestGroup,\n                                \"A\" = \"Group A\",\n                                \"B\" = \"Group B\",\n                                \"C\" = \"Group C\",\n                                \"D\" = \"Group D\",\n                                \"E\" = \"Group E\",\n                                \"F\" = \"Group F\",\n                                \"G\" = \"Group G\",\n                                \"H\" = \"Group H\",\n                                \"I\" = \"Group I\",\n                                \"J\" = \"Group J\"))\n\nparticipants <- participants %>%\n  mutate(haveKids = if_else(haveKids == \"TRUE\", TRUE, FALSE)) # Convert \"TRUE\" and \"FALSE\" to boolean TRUE and FALSE\n\nNext, we need to validate the “timestamp” variable in the “financial_journal” dataset, so I converted the “timestamp” column to a proper datetime format\n\nJournal$timestamp <- as.POSIXct(Journal$timestamp, format = \"%Y-%m-%d %H:%M:%S\")\n\nNow all the seems to be cleaned, lets take a quick look at each table:\n\nhead(Journal)\n\n# A tibble: 6 × 4\n  participantId timestamp           category  amount\n          <dbl> <dttm>              <chr>      <dbl>\n1             0 2022-03-01 00:00:00 Wage      2473. \n2             0 2022-03-01 00:00:00 Shelter   -555. \n3             0 2022-03-01 00:00:00 Education  -38.0\n4             1 2022-03-01 00:00:00 Wage      2047. \n5             1 2022-03-01 00:00:00 Shelter   -555. \n6             1 2022-03-01 00:00:00 Education  -38.0\n\n\n\nhead(participants)\n\n# A tibble: 6 × 7\n  participantId householdSize haveKids   age educationLevel        interestGroup\n          <dbl>         <dbl> <lgl>    <dbl> <chr>                 <chr>        \n1             0             3 TRUE        36 High School or Colle… Group H      \n2             1             3 TRUE        25 High School or Colle… Group B      \n3             2             3 TRUE        35 High School or Colle… Group A      \n4             3             3 TRUE        21 High School or Colle… Group I      \n5             4             3 TRUE        43 Bachelors             Group H      \n6             5             3 TRUE        32 High School or Colle… Group D      \n# ℹ 1 more variable: joviality <dbl>\n\n\nNow that the data cleaning steps have been completed, we can proceed with Exploratory Data Analysis (EDA)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#descriptive-statistics",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#descriptive-statistics",
    "title": "Unveiling Demographic and Financial Characteristics of City of Engagement: A Visual Analysis driven Study",
    "section": "Descriptive statistics",
    "text": "Descriptive statistics\nTo compute descriptive statistics for numerical variables in R, we can use the summary() function.\nHere’s how I create plots for the variables in the participants dataframe and the Journal dataframe using the ggplot2 package in R:\n\n# Histogram for age\nhistogram_age <- ggplot(participants, aes(x = age)) +\n  geom_histogram(fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribution of Age\", x = \"Age\", y = \"Count\")\n\n# Bar plot for educationLevel\nbarplot_education <- ggplot(participants, aes(x = educationLevel)) +\n  geom_bar(fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribution of Education Level\", x = \"Education Level\", y = \"Count\")\n\n# Bar plot for interestGroup\nbarplot_interest <- ggplot(participants, aes(x = interestGroup)) +\n  geom_bar(fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribution of Interest Group\", x = \"Interest Group\", y = \"Count\")\n\n# Calculate median joviality for each age group\nmedian_joviality <- participants %>%\n  group_by(age) %>%\n  summarize(median_joviality = median(joviality))\n\n# Plot median joviality by age group\nscatterplot_age_joviality <- ggplot(median_joviality, aes(x = age, y = median_joviality)) +\n  geom_line() +\n  labs(title = \"Median Joviality by Age Group\", x = \"Age\", y = \"Median Joviality\")\n\n# Arrange plots in a grid\ngrid.arrange(histogram_age, barplot_education, barplot_interest, scatterplot_age_joviality,\n             nrow = 2, ncol = 2)\n\n\n\n\nFor the Age, the distribution seems very rather smooth with no clear peak or hump of a group age, it jumps up and down in between ages with no concentrated point.\nFor the Education level, people who have high school or college level appears to be most common.\nFor the interest group and median joviality, either of them appear to have any normal distribution symptom.\n\n# Box plot for amount\nboxplot_amount <- ggplot(Journal, aes(x = \"\", y = amount)) +\n  geom_boxplot(fill = \"lightblue\", color = \"black\", outlier.shape = NA) +\n  coord_cartesian(ylim = c(-10, 50)) +  # Set the y-axis limits as desired\n  labs(title = \"Distribution of Amount\", x = \"\", y = \"Amount\")\n\n# Bar plot for category\nbarplot_category <- ggplot(Journal, aes(x = category)) +\n  geom_bar(fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribution of Expense Categories\", x = \"Category\", y = \"Count\")\n\n# Plot total amount spent per month\nJournal$month <- floor_date(Journal$timestamp, \"month\")\nmonthly_totals <- Journal %>%\n  group_by(month) %>%\n  summarize(total_amount = sum(amount))\n\nlineplot_total_amount <- ggplot(monthly_totals, aes(x = month, y = total_amount)) +\n  geom_line() +\n  labs(title = \"Total Amount Spent per Month\", x = \"Month\", y = \"Total Amount\")\n\n# Arrange plots in a grid\ngrid.arrange(boxplot_amount, barplot_category, lineplot_total_amount,\n             nrow = 2, ncol = 2)\n\n\n\n\nFor the amount, as it concentrated towards the 0, it means the amount of transactions are mostly small.\nFor the Expense category, the transaction categories are mostly on food, recreation, and wages.\nFor the total amount spent per month, except for before April 2022, all other time spam seems quite smooth with transaction amount."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#relationships-between-variables",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#relationships-between-variables",
    "title": "Unveiling Demographic and Financial Characteristics of City of Engagement: A Visual Analysis driven Study",
    "section": "Relationships between variables",
    "text": "Relationships between variables\nAfter finishing the descriptive statistics, let’s move on to exploring the relationships between variables. Understanding the relationships between variables can provide valuable insights into the data and help uncover interesting patterns or associations.\nIn order for a better comparison and visualization in between variables, we should join the dtaframe:\n\n# Join the participants and financial_journal dataframes\nmerged_data <- participants %>%\n  inner_join(Journal, by = \"participantId\")\n\n# Check for missing values in the age variable\nmissing_age <- sum(is.na(merged_data$age))\n\n# Print the number of missing values\nprint(paste(\"Number of missing values in age:\", missing_age))\n\n[1] \"Number of missing values in age: 0\"\n\n# Filter out the rows with missing values in age\nmerged_data <- merged_data[!is.na(merged_data$age), ]\n\n\nAge and Joviality\n\n# Define the age groups\nage_groups <- c(\"18-25\", \"26-35\", \"36-45\", \"46-55\", \"56+\")\n\n# Create a new variable for age groups\nmerged_data <- merged_data %>%\n  mutate(age_group = cut(age, breaks = c(18, 25, 35, 45, 55, Inf), labels = age_groups))\n\n# Box plot for age groups and joviality\nggplot(merged_data, aes(x = age_group, y = joviality)) +\n  geom_boxplot() +\n  labs(title = \"Joviality by Age Group\", x = \"Age Group\", y = \"Joviality\")\n\n\n\n# Calculate summary statistics by age group\nsummary_age <- merged_data %>%\n  group_by(age_group) %>%\n  summarize(\n    mean_joviality = mean(joviality),\n    median_joviality = median(joviality),\n    min_joviality = min(joviality),\n    max_joviality = max(joviality)\n  )\n\n# Print the summary statistics\nprint(summary_age)\n\n# A tibble: 6 × 5\n  age_group mean_joviality median_joviality min_joviality max_joviality\n  <fct>              <dbl>            <dbl>         <dbl>         <dbl>\n1 18-25              0.511            0.503      0.00137          0.986\n2 26-35              0.508            0.504      0.000985         0.999\n3 36-45              0.516            0.521      0.00163          0.998\n4 46-55              0.440            0.429      0.000265         0.999\n5 56+                0.510            0.491      0.000204         0.992\n6 <NA>               0.571            0.597      0.108            0.987\n\n\nBased on the summary statistics for the age groups and joviality, we can interpret the results as follows:\n\nAge Group “18-25”:\n\nMean Joviality: 0.511\nMedian Joviality: 0.503\nMinimum Joviality: 0.001\nMaximum Joviality: 0.986\n\nAge Group “26-35”:\n\nMean Joviality: 0.508\nMedian Joviality: 0.504\nMinimum Joviality: 0.001\nMaximum Joviality: 0.999\n\nAge Group “36-45”:\n\nMean Joviality: 0.516\nMedian Joviality: 0.521\nMinimum Joviality: 0.002\nMaximum Joviality: 0.998\n\nAge Group “46-55”:\n\nMean Joviality: 0.440\nMedian Joviality: 0.429\nMinimum Joviality: 0.000\nMaximum Joviality: 0.999\n\nAge Group “56+”:\n\nMean Joviality: 0.510\nMedian Joviality: 0.491\nMinimum Joviality: 0.000\nMaximum Joviality: 0.992\n\n\nThese statistics provide an overview of the joviality levels within each age group. Here are some key observations:\n\nThe mean joviality levels are relatively consistent across the age groups, ranging from approximately 0.440 to 0.516.\nThe median joviality levels show a similar pattern, with values ranging from around 0.429 to 0.521.\nThe minimum and maximum joviality levels vary within each age group, indicating the range of joviality experienced by individuals in each group.\nOverall, there doesn’t seem to be a clear trend or pattern in joviality levels across age groups based on these summary statistics.\n\n\n\nHousehold Size and Education Level\n\n# Bar plot for household size and education level\nggplot(merged_data, aes(x = householdSize, fill = educationLevel)) +\n  geom_bar() +\n  labs(title = \"Household Size by Education Level\", x = \"Household Size\", y = \"Count\") +\n  scale_fill_discrete(name = \"Education Level\")\n\n\n\n\nFrom the plot above, it appears that the majority of households in the dataset have a household size of 1 or 2. Additionally, the “High School or College” education level seems to be the most prevalent across all household sizes.\nThis suggests a possible correlation between household size and education level. It is likely that individuals living alone or in smaller households (size 1 or 2) are more likely to have completed high school or attended college, as reflected by the higher count in the “High School or College” category for these household sizes.\nOn the other hand, larger household sizes (beyond size 2) may include a mix of different education levels, as evidenced by the presence of “Bachelors” and “Graduate” categories in these groups. This suggests a less diversity of education levels within larger households.\n\n\nEducation Level and Joviality\n\n# Box plot for education level and joviality\nggplot(merged_data, aes(x = educationLevel, y = joviality)) +\n  geom_boxplot() +\n  labs(title = \"Joviality by Education Level\", x = \"Education Level\", y = \"Joviality\")\n\n\n\n\nBased on these results, we can make a scientific guess that individuals with higher education levels, such as “Graduate” and “Bachelors,” tend to have higher median joviality scores compared to those with lower education levels, such as “Low” and “High School or College.” Additionally, individuals with higher education levels generally have a wider range of joviality values, as indicated by the larger differences between the minimum and maximum joviality values.\n\n\nInterest Group and Joviality\n\n# Box plot for interest group and joviality\nggplot(merged_data, aes(x = interestGroup, y = joviality)) +\n  geom_boxplot() +\n  labs(title = \"Joviality by Interest Group\", x = \"Interest Group\", y = \"Joviality\")\n\n\n\n\nBased on these results, we can make a scientific guess that different interest groups may have varying levels of median joviality. For example, “Group E” and “Group B” have relatively higher median joviality compared to “Group H” and “Group D.” However, it’s important to note that there could be other factors influencing joviality, and this analysis only considers the provided data.\n\n\nHousehold Size and Amount\n\n# Scatter plot for household size and amount\nggplot(merged_data, aes(x = as.factor(householdSize), y = amount, fill = as.factor(householdSize))) +\n  geom_bar(stat = \"summary\", fun = \"mean\", position = \"dodge\") +\n  labs(title = \"Mean Amount by Household Size\", x = \"Household Size\", y = \"Mean Amount\") +\n  scale_fill_discrete(name = \"Household Size\")\n\n\n\n\nBased on these results, we can make a scientific analysis that households with larger sizes tend to have slightly higher mean amounts compared to smaller households. However, it’s important to note that the median amount is the same for all household sizes, suggesting a similar distribution of amounts regardless of household size.\nAdditionally, the range of amounts spent varies across different household sizes, as indicated by the differences in the minimum and maximum amounts. This implies that there might be variations in spending habits and financial situations among households of different sizes.\n\n\nEducation Level and Amount\n\n# Box plot for education level and amount\nggplot(merged_data, aes(x = educationLevel, y = amount, fill = educationLevel)) +\n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter(aes(color = educationLevel), width = 0.2, height = 0, alpha = 0.5) +\n  labs(title = \"Distribution of Amount by Education Level\", x = \"Education Level\", y = \"Amount\") +\n  scale_fill_discrete(name = \"Education Level\") +\n  scale_color_discrete(name = \"Education Level\")\n\n\n\n\nBased on these results, we can make a scientific analysis that individuals with higher education levels, such as “Graduate” and “Bachelors,” tend to have higher maximum amounts spent compared to those with lower education levels, such as “Low” and “High School or College.”\nThe data reveals that within each education level group, there are individuals who have higher amounts spent or higher income compared to others in the same group. This suggests that being successful is always a possibility, regardless of education level, as personal circumstances, career choices, skills, networking, and opportunities also play a significant role.Education level is an important factor that can contribute to success and income, but it is not the sole determinant. Education provides knowledge and opportunities, but it does not guarantee automatic financial prosperity. Success is multifaceted and influenced by various factors beyond education alone.\n\n\nInterest Group and Amount\n\n# Box plot for interest group and amount\nggplot(merged_data, aes(x = interestGroup, y = amount, fill = interestGroup)) +\n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter(aes(color = interestGroup), width = 0.2, height = 0, alpha = 0.5) +\n  labs(title = \"Distribution of Amount by Interest Group\", x = \"Interest Group\", y = \"Amount\") +\n  scale_fill_discrete(name = \"Interest Group\") +\n  scale_color_discrete(name = \"Interest Group\")\n\n\n\n\nThere appears no distinct and big differences across different interest groups, except fir B, C, D, E, G and J, there is a small chunk of them that plots right above the majority, indicating that there might be a specific class within the interest groups.\n\n\nAge and Amount\n\n# Scatter plot for age and amount\nggplot(merged_data, aes(x = age_group, y = amount, fill = age_group)) +\n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter(aes(color = age_group), width = 0.2, height = 0, alpha = 0.5) +\n  labs(title = \"Distribution of Amount by Age Group\", x = \"Age Group\", y = \"Amount\") +\n  scale_fill_discrete(name = \"Age Group\") +\n  scale_color_discrete(name = \"Age Group\")\n\n\n\n\nFor the age group and the expenses plot, it appears to have a similar pattern with the previous two plots. While distinct classes are found, indicates age might not be de determinant factor of different class.\nAnalyzing the relationship between age group and financial outcomes is complex and multidimensional. It requires considering a broader range of variables and conducting more in-depth statistical analyses to gain a comprehensive understanding of the factors influencing success and income.\n\n\nEducation Level and Expenses Category\n\n# Bar plot for education level and expense category (mean expenses)\nggplot(merged_data, aes(x = educationLevel, y = amount, fill = category)) +\n  stat_summary(fun = \"mean\", geom = \"bar\", position = \"dodge\") +\n  labs(title = \"Mean Expense Category by Education Level\", x = \"Education Level\", y = \"Mean Expense\") +\n  scale_fill_discrete(name = \"Expense Category\")\n\n\n\n\nFor individuals with a Graduate level of education, the mean amount spent on wages appears to be the highest among all expense categories. Additionally, the highest mean spending in the “Shelter” category suggests that individuals with a Graduate degree allocate a significant portion of their expenses towards their living arrangements.\nFor individuals with a Bachelor’s degree, the “RentAdjustment” category tends to have the highest mean amount compared to other expense categories. This indicates that individuals with a high level of education, such as a Bachelor’s degree, allocate a larger proportion of their expenses towards adjusting their rent.\nOn the other hand, for individuals with a low education level, the mean spending on shelter is the lowest among all groups. This implies that individuals with lower education levels tend to allocate less money towards their living environment or housing expenses. In other words, lower education levels may play a role in determining lower spending on shelter, indicating potential differences in financial capabilities and living conditions based on educational attainment.\n\n\nInterest Group and Expense Category\n\n# Bar plot for interest group and expense category (mean values)\nggplot(merged_data, aes(x = interestGroup, fill = category)) +\n  stat_summary(aes(y = amount, group = category), fun = \"mean\", geom = \"bar\") +\n  labs(title = \"Mean Expense Category by Interest Group\", x = \"Interest Group\", y = \"Mean Count\") +\n  scale_fill_discrete(name = \"Expense Category\")\n\n\n\n\nFor interest groups E, G, and I, the mean count for the “RentAdjustment” category appears to be relatively low compared to other interest groups. This suggests that individuals in these groups, on average, spend less on adjusting their rent compared to individuals in other interest groups.\nConversely, interest group H shows a significant difference in renting behavior. The mean count for the “RentAdjustment” category is notably higher in group H compared to other interest groups. This indicates that individuals in interest group H, on average, allocate a larger portion of their expenses towards adjusting their rent.\nFor other expense categories, such as “Education,” “Food,” “Recreation,” and others, there are no significant differences observed across the interest groups. The mean counts for these categories appear to be relatively similar, suggesting that individuals in different interest groups have comparable spending patterns in these areas."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#age-vs.-joviality",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#age-vs.-joviality",
    "title": "Unveiling Demographic and Financial Characteristics of City of Engagement: A Visual Analysis driven Study",
    "section": "Age vs. Joviality",
    "text": "Age vs. Joviality\n\n# Create an interactive scatter plot with tooltips\nplot1 <- plot_ly(data = participants, x = ~age, y = ~joviality, color = ~educationLevel,\n             text = ~paste(\"Participant ID:\", participantId, \"<br>\",\n                           \"Education Level:\", educationLevel, \"<br>\",\n                           \"Interest Group:\", interestGroup),\n             hoverinfo = \"text\",\n             type = \"scatter\", mode = \"markers\") %>%\n  layout(title = \"Interactive Scatter Plot: Age vs. Joviality\",\n         xaxis = list(title = \"Age\"),\n         yaxis = list(title = \"Joviality\"))\n\n# Display the interactive plot\nplot1\n\n\n\n\n\nThe resulting plot allows users to interact with the data points by hovering over them to view additional information. The scatter plot visualizes the relationship between age and joviality, with each data point represented by a marker color-coded based on the education level. This interactive plot provides a dynamic way to explore and analyze the data."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#joviality-over-time",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#joviality-over-time",
    "title": "Unveiling Demographic and Financial Characteristics of City of Engagement: A Visual Analysis driven Study",
    "section": "Joviality over Time",
    "text": "Joviality over Time\n\nset.seed(1234)  # Set a specific seed value\n\n# Subsample the dataset\nsample_size <- 2000  # Adjust the sample size as needed\nsubsample <- merged_data %>% sample_n(sample_size)\n\n# Calculate the moving average of joviality for each education level\nmoving_average_data <- subsample %>%\n  arrange(timestamp) %>%\n  group_by(educationLevel) %>%\n  mutate(moving_avg_joviality = zoo::rollmean(joviality, k = 10, fill = NA))\n\nplot2 <- ggplot(moving_average_data, aes(x = timestamp, y = moving_avg_joviality, color = educationLevel)) +\n  geom_line(size = 1, lineend = \"round\", na.rm = TRUE) +\n  scale_color_manual(values = c(\"#FF0000\", \"#00FF00\", \"#0000FF\", \"#FFFF00\"), name = \"Education Level\") +\n  labs(title = \"Moving Average of Joviality by Education Level over Time\", x = \"Timestamp\", y = \"Moving Average Joviality\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  transition_reveal(timestamp) +\n  ease_aes('linear')\n\n# Animate and display the plot\nanim1 <- animate(plot2, nframes = 200, fps = 5, end_pause = 20)\nanim_save(\"animated_plot1.gif\", anim1)\nanim1\n\n\n\n\nThe animated line chart shows the moving average of joviality over time, with separate lines for each education level. The animation creates a dynamic view of how the moving average of joviality changes over time for each education level.\nA moving average smooths out short-term fluctuations and highlights longer-term trends in the data. In this case, we use a window of 10 data points for calculating the moving average. The moving average of joviality for each education level is calculated at each timestamp within the given window.\nHere’s a brief interpretation of the plot:\n\nX-axis (Timestamp): Represents the time variable, showing the progression of the data over time.\nY-axis (Moving Average Joviality): Represents the moving average of joviality calculated for each education level at each timestamp. The moving average smooths out the short-term fluctuations in joviality and highlights the overall trend.\nColor-coded lines (Education Level): Each line in the plot represents a different education level. The color-coding allows you to easily distinguish between the education levels and observe their trends in joviality over time.\n\nIn the animation, the “Graduate” group consistently shows higher moving average joviality compared to the other groups, while the “High school and college” group consistently shows lower moving average joviality. This observation suggests that there is a noticeable difference in joviality between these two education levels.\nThe animated line chart reveals that although there is no significant overall increase or decrease in joviality across different education levels, there are numerous fluctuations along the way. This observation implies that people’s happiness or joviality is subject to constant change."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#expenses-and-food-over-time",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#expenses-and-food-over-time",
    "title": "Unveiling Demographic and Financial Characteristics of City of Engagement: A Visual Analysis driven Study",
    "section": "Expenses and Food Over Time",
    "text": "Expenses and Food Over Time\n\n# Convert timestamp to date format\nmerged_data$date <- as.Date(merged_data$timestamp)\n\n# Filter expenses and wages data\nexpenses <- merged_data[merged_data$category != \"Food\", ]\nfood <- merged_data[merged_data$category == \"Food\", ]\n\n# Create a line plot of total expenses over time\nplot3 <- ggplot() +\n  geom_line(data = expenses, aes(x = date, y = amount, color = \"Expenses\"), size = 1) +\n  geom_line(data = food, aes(x = date, y = amount, color = \"Food\"), size = 3) +\n  labs(title = \"Expenses and Food Over Time\", x = \"Date\", y = \"Amount\", color = \"Category\") +\n  scale_color_manual(values = c(\"Expenses\" = \"blue\", \"Food\" = \"green\")) +\n  coord_cartesian(ylim = c(-100, 1000)) +  # Adjust the y-axis limit\n  transition_time(date) +\n  ease_aes(\"linear\")\n\n# Animate the plot\nanim2 <- animate(plot3, nframes = 200, duration = 10)\nanim_save(\"animated_plot2.gif\", anim2, fps = 10)\nanim2\n\n\n\n\nThis plot displays the trends in expenses and food expenses over a specific time period. The x-axis represents the date, while the y-axis represents the amount of expenses. The plot includes two lines: one representing total expenses and the other representing food expenses.\nThe blue line represents the total expenses, showing the overall trend in expenses over time. The green line represents food expenses, specifically highlighting the trend in spending on food items. By comparing the two lines, we can observe how food expenses contribute to the overall expenses and whether there are any notable patterns or fluctuations.\nThe visualization shows the distribution of expenses over time, with a specific focus on the food category. It is evident that food expenses constitute a relatively small portion of the overall expenses. This observation suggests that individuals in the town allocate a smaller proportion of their budget towards food compared to other expenditure categories."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#age-household-size-and-spending-amount",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#age-household-size-and-spending-amount",
    "title": "Unveiling Demographic and Financial Characteristics of City of Engagement: A Visual Analysis driven Study",
    "section": "Age, Household Size, and Spending Amount",
    "text": "Age, Household Size, and Spending Amount\nK-means clustering was chosen as the method for analyzing the variables age, household size, and spending amount. This approach provides a straightforward and efficient way to identify distinct groups based on similarities in these variables. By clustering individuals based on age, we can explore if there are any age-related patterns in household size and spending amount. The clustering of household size allows us to examine if different household sizes exhibit unique spending behaviors. Additionally, clustering individuals based on spending amount helps identify distinct spending profiles or segments within the population. Overall, the application of k-means clustering on age, household size, and spending amount enables us to uncover underlying patterns and relationships, assisting in targeted decision-making and strategy development based on different age groups, household sizes, and spending patterns.\n\nset.seed(123)  # Set a specific seed value\n\n# Perform cluster analysis using k-means\ndata_for_kmeans <- merged_data %>%\n  select(age, householdSize, amount)\n\n# Standardize the variables\nscaled_data <- scale(data_for_kmeans)\n\n# Determine the optimal number of clusters using the elbow method\nwss <- numeric(10)\nfor (k in 1:10) {\n  model <- kmeans(scaled_data, centers = k)\n  wss[k] <- sum(model$withinss)\n}\n\n# Perform k-means clustering with the chosen number of clusters\nk <- 3  # Choose the number of clusters based on the elbow plot\nkmeans_model <- kmeans(scaled_data, centers = k)\n\n# Add the cluster assignments to the original dataset\nmerged_data$Kmeans_cluster <- as.factor(kmeans_model$cluster)\n\n# Calculate cluster means\nKmeans_summary <- merged_data %>%\n  group_by(Kmeans_cluster) %>%\n  summarize(mean_age = mean(age),\n            mean_householdSize = mean(householdSize),\n            mean_amount = mean(amount))\n\n# Print the cluster summary\nprint(Kmeans_summary)\n\n# A tibble: 3 × 4\n  Kmeans_cluster mean_age mean_householdSize mean_amount\n  <fct>             <dbl>              <dbl>       <dbl>\n1 1                  34.5               2.61       -2.13\n2 2                  40.4               2.20      212.  \n3 3                  42.7               1.26        6.49\n\n\n\n# Prepare the data for visualization\nkmeans_plot <- merged_data %>%\n  select(age, householdSize, amount, Kmeans_cluster)\n\n# Create the scatterplot matrix\nkmeans_matrix <- ggpairs(kmeans_plot, columns = c(\"age\", \"householdSize\", \"amount\"), mapping = aes(color = Kmeans_cluster), alpha = 0.6) +\n  theme_minimal() +\n  labs(title = \"Cluster Analysis: K-means\", color = \"Cluster\") +\n  scale_color_manual(values = c(\"blue\", \"green\", \"red\")) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Display the scatterplot matrix\nkmeans_matrix\n\n\n\n\n\n# Create bubble plot\nggplot(Kmeans_summary, aes(x = mean_age, y = mean_householdSize, size = mean_amount, color = Kmeans_cluster)) +\n  geom_point(alpha = 0.8) +\n  labs(title = \"Cluster Analysis: Age, Household Size, and Spending Amount\",\n       x = \"Average Age\",\n       y = \"Average Household Size\",\n       color = \"Cluster\",\n       size = \"Average Spending Amount\") +\n  scale_size(range = c(5, 15)) +\n  theme_minimal()\n\n\n\n\n\nCluster 1:\nMean Age: 34.53\nMean Household Size: 2.61\nMean Amount: -2.13\nCluster 1: This cluster has a relatively younger population with a mean age of 34.53. The average household size is 2.61, suggesting that individuals in this cluster tend to live in larger households. The mean amount is -2.13, indicating that on average, individuals in this cluster have lower spending amounts.\nThis cluster represents relatively younger individuals who live in larger households. They have lower spending amounts compared to the other clusters. This group may include young adults or families who are more cautious with their expenses and prioritize saving.\nCluster 2:\nMean Age: 40.43\nMean Household Size: 2.20\nMean Amount: 212.26\nCluster 2: This cluster has a slightly older population with a mean age of 40.43. The average household size is 2.20, suggesting that individuals in this cluster tend to live in smaller households. The mean amount is 212.26, indicating that on average, individuals in this cluster have higher spending amounts.\nThis cluster consists of slightly older individuals who live in smaller households. They have higher spending amounts, suggesting that they may have higher incomes or different spending priorities. This group might include established professionals or affluent individuals who can afford to spend more on various expenses.\nCluster 3:\nMean Age: 42.71\nMean Household Size: 1.26\nMean Amount: 6.49\nCluster 3: This cluster has an older population with a mean age of 42.71. The average household size is 1.26, indicating that individuals in this cluster tend to live alone or in smaller households. The mean amount is 6.49, suggesting that on average, individuals in this cluster have moderate spending amounts.\nThis cluster represents older individuals who live alone or in smaller households. They have moderate spending amounts, indicating a balanced approach to expenses. This group could include retirees or individuals who have a more frugal lifestyle, focusing on essential needs rather than extravagant spending."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#age-household-size-joviality-and-education-level",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#age-household-size-joviality-and-education-level",
    "title": "Unveiling Demographic and Financial Characteristics of City of Engagement: A Visual Analysis driven Study",
    "section": "Age, Household Size, Joviality and Education Level",
    "text": "Age, Household Size, Joviality and Education Level\nThe fanny algorithm was selected for analyzing the variables of age, household size, joviality, and education level. Fanny, a variant of k-means clustering, is particularly suitable for categorical variables such as education level. By incorporating education level as a categorical variable, we can explore the relationship between demographic factors (age and household size) and psychological well-being (joviality) within different educational groups. Fanny algorithm allows for a more flexible clustering approach by accommodating mixed variable types, enabling us to uncover distinct clusters based on these diverse dimensions. This approach provides a comprehensive understanding of how age, household size, joviality, and education level interrelate, allowing for targeted interventions and tailored strategies to address specific needs within different demographic and educational segments of the population.\nGiven the high computational requirements of cluster analysis, a subsample of 5000 observations was chosen to expedite the analysis process. By working with a smaller subset, the computational time was significantly reduced while still allowing for meaningful insights. It is important to note that the subsample should be representative of the larger dataset, capturing its key characteristics and variability. The use of a subsample should be clearly documented and acknowledged to ensure transparency in the analysis.\n\nset.seed(1234)  # Set a specific seed value\n\n# Subsample the dataset\nsample_size <- 5000  # Adjust the sample size as needed\nsubsample <- merged_data %>% sample_n(sample_size)\n\n# Select variables for cluster analysis\ndata_for_fanny <- subsample %>%\n  select(age, householdSize, joviality, educationLevel)\n\n# Convert education level to numeric labels\ndata_for_fanny$educationLabel <- as.factor(data_for_fanny$educationLevel)\n\n# Standardize the numeric variables\nscaled_data <- scale(data_for_fanny[, c(\"age\", \"householdSize\", \"joviality\")])\n\n# Perform clustering with Fanny algorithm\nk <- 4  # Number of clusters\nfanny_model <- fanny(scaled_data, k, memb.exp = 1.1)\n\n# Add the cluster assignments to the subsample dataset\nsubsample$cluster <- as.factor(fanny_model$clustering)\n\n# Calculate cluster means\nfanny_summary <- subsample %>%\n  group_by(cluster) %>%\n  summarize(mean_age = mean(age),\n            mean_householdSize = mean(householdSize),\n            mean_joviality = mean(joviality),\n            mean_educationLevel = levels(data_for_fanny$educationLabel)[which.max(table(data_for_fanny$educationLabel))])\n\n# Print the cluster summary\nprint(fanny_summary)\n\n# A tibble: 4 × 5\n  cluster mean_age mean_householdSize mean_joviality mean_educationLevel   \n  <fct>      <dbl>              <dbl>          <dbl> <chr>                 \n1 1           30.6               1.51          0.799 High School or College\n2 2           51.7               1.47          0.463 High School or College\n3 3           30.1               1.56          0.254 High School or College\n4 4           38.3               3             0.477 High School or College\n\n\n\n# Create a scatterplot matrix\nplot <- ggpairs(subsample,\n                columns = c(\"age\", \"householdSize\", \"joviality\", \"educationLevel\"),\n                mapping = ggplot2::aes(color = cluster)) +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\")\n\n# Display the plot\nprint(plot)\n\n\n\n\n\nfanny_plot <- plot_ly() %>%\n  add_trace(data = subsample,\n            x = ~age,\n            y = ~householdSize,\n            z = ~joviality,\n            type = \"scatter3d\",\n            mode = \"markers\",\n            marker = list(size = 3,\n                          color = ~as.numeric(cluster),\n                          colorscale = \"Viridis\"),\n            text = ~paste0(\"Cluster: \", cluster)) %>%\n  layout(scene = list(xaxis = list(title = \"Age\"),\n                      yaxis = list(title = \"Household Size\"),\n                      zaxis = list(title = \"Joviality\")),\n         title = \"3D Scatterplot of Clusters\")\n\nprint(fanny_plot)\n\nCluster 1:\nMean Age: 30.57\nMean Household Size: 1.51\nMean Joviality: 0.799\nMean Education Level: High School or College\nCluster 1: This cluster represents individuals with a mean age of 30.57, relatively smaller household sizes of 1.51, and a higher level of joviality with a mean of 0.799. The majority of individuals in this cluster have a high school or college education level.\nThis group might include young adults who are generally cheerful and have smaller households. They could be at a stage in life where they are focused on personal growth, career development, and building relationships. Their higher level of joviality might be influenced by their youthful energy and optimism.\nCluster 2:\nMean Age: 51.67\nMean Household Size: 1.47\nMean Joviality: 0.463\nMean Education Level: High School or College\nCluster 2: This cluster consists of individuals with a mean age of 51.67 and relatively smaller household sizes of 1.47. They have a lower level of joviality with a mean of 0.463. Similar to other clusters, the majority of individuals in this cluster also have a high school or college education level.\nThis group might represent older individuals who tend to be less jovial but have smaller households. They might be in a stage of life where they have more responsibilities, such as taking care of family or managing their careers. Their lower level of joviality might be influenced by life experiences and responsibilities.\nCluster 3:\nMean Age: 30.06\nMean Household Size: 1.56\nMean Joviality: 0.254\nMean Education Level: High School or College\nCluster 3: This cluster represents individuals with a mean age of 30.06 and slightly larger household sizes of 1.56. They have a lower level of joviality with a mean of 0.254. Similar to the other clusters, the majority of individuals in this cluster have a high school or college education level.\nThis group might include younger individuals with slightly larger households but lower joviality levels. They could be in a stage of life where they are starting families or building their careers. Their lower level of joviality might be influenced by the challenges and responsibilities they face as they transition into adulthood.\nCluster 4:\nMean Age: 38.31\nMean Household Size: 3.00\nMean Joviality: 0.477\nMean Education Level: High School or College\nCluster 4: This cluster consists of individuals with a mean age of 38.31 and larger household sizes of 3.00. They have a moderate level of joviality with a mean of 0.477. Similar to other clusters, the majority of individuals in this cluster have a high school or college education level.\nThis group might represent individuals with larger families who tend to be moderately jovial. They could be in a stage of life where they are actively managing their family life, balancing multiple responsibilities, and engaging in social interactions. Their moderate level of joviality might be influenced by their family dynamics and social connections."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary",
    "title": "Unveiling Demographic and Financial Characteristics of City of Engagement: A Visual Analysis driven Study",
    "section": "Summary",
    "text": "Summary\nBased on the cluster analysis findings, we have identified distinct groups within the dataset based on demographic and behavioral characteristics. The analysis revealed variations in age, household size, spending patterns, and education level among the clusters. These findings provide valuable insights into the different segments within the dataset and can be used to understand the diversity among individuals in terms of their financial behaviors and characteristics. The identified clusters can help inform targeted marketing strategies, personalized financial planning, and decision-making processes to better meet the specific needs and preferences of individuals within each cluster. Overall, the cluster analysis has provided a deeper understanding of the dataset and offers valuable information for making data-driven business and financial decisions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "The code chunk below will be used to install and load the necessary R packages to meet the data preparation, data wrangling, data analysis and visualisation needs.\n\npacman::p_load(jsonlite, tidygraph, ggraph, GGally, wordcloud, visNetwork,\n               visNetwork, graphlayouts, ggforce, igraph, ggraph,\n               skimr, tidytext, tidyverse, gganimate, gridExtra)\n\n\n\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC3.json into R environment.\n\nmc3_data <- fromJSON(\"data/MC3.json\")\n\nThe output is called mc3_data. It is a large list R object.\n\n\n\n\n\nThe code chunk below will be used to extract the links data.frame of mc3_data and save it as a tibble data.frame called mc3_edges.\n\nmc3_edges <- as_tibble(mc3_data$links) %>% \n  distinct() %>%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %>%\n  group_by(source, target, type) %>%\n    summarise(weights = n()) %>%\n  filter(source!=target) %>%\n  ungroup()\n\n\n\n\nThe code chunk below will be used to extract the nodes data.frame of mc3_data and save it as a tibble data.frame called mc3_nodes.\n\nmc3_nodes <- as_tibble(mc3_data$nodes) %>%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %>%\n  select(id, country, type, revenue_omu, product_services)\n\n\n\n\n\n\n\nIn the code chunk below, skim() of skimr package is used to display the summary statistics of mc3_edges tibble data frame.\n\nskim(mc3_edges)\n\n\nData summary\n\n\nName\nmc3_edges\n\n\nNumber of rows\n24036\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsource\n0\n1\n6\n700\n0\n12856\n0\n\n\ntarget\n0\n1\n6\n28\n0\n21265\n0\n\n\ntype\n0\n1\n16\n16\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nweights\n0\n1\n1\n0\n1\n1\n1\n1\n1\n▁▁▇▁▁\n\n\n\n\n\nThe report above reveals that there is not missing values in all fields.\nIn the code chunk below, glimpse() of DT package is used to display mc3_edges.\n\nglimpse(mc3_edges)\n\nRows: 24,036\nColumns: 4\n$ source  <chr> \"1 AS Marine sanctuary\", \"1 AS Marine sanctuary\", \"1 Ltd. Liab…\n$ target  <chr> \"Christina Taylor\", \"Debbie Sanders\", \"Angela Smith\", \"Catheri…\n$ type    <chr> \"Company Contacts\", \"Beneficial Owner\", \"Beneficial Owner\", \"C…\n$ weights <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\n\n\nggplot(data = mc3_edges,\n       aes(x = type)) +\n  geom_bar()\n\n\n\n\n\n\n\nIn the code chunk below, skim() of skimr package is used to display the summary statistics of mc3_nodes tibble data frame.\n\nskim(mc3_nodes)\n\n\nData summary\n\n\nName\nmc3_nodes\n\n\nNumber of rows\n27622\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nid\n0\n1\n6\n64\n0\n22929\n0\n\n\ncountry\n0\n1\n2\n15\n0\n100\n0\n\n\ntype\n0\n1\n7\n16\n0\n3\n0\n\n\nproduct_services\n0\n1\n4\n1737\n0\n3244\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrevenue_omu\n21515\n0.22\n1822155\n18184433\n3652.23\n7676.36\n16210.68\n48327.66\n310612303\n▇▁▁▁▁\n\n\n\n\n\n\nglimpse(mc3_nodes)\n\nRows: 27,622\nColumns: 5\n$ id               <chr> \"Jones LLC\", \"Coleman, Hall and Lopez\", \"Aqua Advance…\n$ country          <chr> \"ZH\", \"ZH\", \"Oceanus\", \"Utoporiana\", \"ZH\", \"ZH\", \"Rio…\n$ type             <chr> \"Company\", \"Company\", \"Company\", \"Company\", \"Company\"…\n$ revenue_omu      <dbl> 310612303, 162734684, 115004667, 90986413, 81466667, …\n$ product_services <chr> \"Automobiles\", \"Passenger cars, trucks, vans, and bus…\n\n\n\nggplot(data = mc3_nodes,\n       aes(x = type)) +\n  geom_bar()\n\n\n\n\n\n# Create a subset of data with 'country' and 'type' variables, excluding 'ZH' entries\nsubset_data <- mc3_nodes[mc3_nodes$country != \"ZH\", c(\"country\", \"type\")]\n\n# Create the parallel coordinates plot with modified parameters\nparallel_plot <- ggparcoord(data = subset_data,\n                            scale = \"uniminmax\",\n                            alphaLines = 0.5) +\n  theme_minimal() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank()) +\n  theme(plot.background = element_blank(),\n        panel.background = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  ylab(\"Type\")\n\n# Create the pie chart\npie_chart <- ggplot(subset_data, aes(x = \"\", fill = type)) +\n  geom_bar(width = 1) +\n  coord_polar(\"y\", start = 0) +\n  labs(fill = \"Type\") +\n  theme_minimal()\n\n# Arrange the plots side by side\nplots <- grid.arrange(parallel_plot, pie_chart, nrow = 1)\n\n\n\n# Display the plots\nprint(plots)\n\nTableGrob (1 x 2) \"arrange\": 2 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n\n\n\nThe analysis revealed that the majority of the entries in the dataset are classified as “Company Type,” while only a few entries are categorized as “Company Contacts” and “Beneficial Owner.”\n\n# Subset the data for each type\ntype1_data <- subset(mc3_nodes, type == \"Company\")\ntype2_data <- subset(mc3_nodes, type == \"Company Contacts\")\ntype3_data <- subset(mc3_nodes, type == \"Beneficial Owner\")\n\n# Create the boxplots for each type\nboxplot1 <- ggplot(type1_data, aes(x = type, y = revenue_omu)) +\n  geom_boxplot(fill = \"lightgreen\", color = \"green\") +\n  labs(x = \"Type 1\", y = \"Revenue\") +\n  theme_minimal()\n\nboxplot2 <- ggplot(type2_data, aes(x = type, y = revenue_omu)) +\n  geom_boxplot(fill = \"lightblue\", color = \"blue\") +\n  labs(x = \"Type 2\", y = \"Revenue\") +\n  theme_minimal()\n\nboxplot3 <- ggplot(type3_data, aes(x = type, y = revenue_omu)) +\n  geom_boxplot(fill = \"pink\", color = \"red\") +\n  labs(x = \"Type 3\", y = \"Revenue\") +\n  theme_minimal()\n\n# Arrange the boxplots side by side\ngrid.arrange(boxplot1, boxplot2, boxplot3, ncol = 3)\n\n\n\n\nFurther exploration of the revenue distribution across different categories revealed interesting patterns. In the “Company” category, there are numerous outliers with significantly higher revenue values, causing the box to appear compressed near the lower end of the scale. On the other hand, the “Company Contacts” category shows a single observation with a revenue value of 157,971, indicating limited variability. Lastly, the “Beneficial Owner” category exhibits a relatively larger range, with a boxplot showing revenue values ranging from 0.5e+08 to 2e+08.\n\n\n\n\nThe code below generates a word cloud visualizing the frequencies of the top 20 words extracted from the ‘source’ and ‘target’ variable in the ‘mc3_edges’ dataset, with larger and bolder words representing higher frequencies.\n\n# Generate word frequencies\nsource_freq <- table(mc3_edges$source)\n\n# Sort word frequencies in descending order\nsorted_source_freq <- sort(source_freq, decreasing = TRUE)\n\n# Select the top 20 words by frequency\ntop_source_words <- names(sorted_source_freq)[1:20]\ntop_source_freq <- sorted_source_freq[1:20]\n\n# Create word cloud with top 20 words\nwordcloud(top_source_words, freq = top_source_freq, scale = c(1.5, 0.2), random.order = FALSE, colors = brewer.pal(8, \"Dark2\"))\n\n\n\n\n\n# Generate word frequencies\ntarget_freq <- table(mc3_edges$target)\n\n# Sort word frequencies in descending order\nsorted_target_freq <- sort(target_freq, decreasing = TRUE)\n\n# Select the top 20 words by frequency\ntop_target_words <- names(sorted_target_freq)[1:20]\ntop_target_freq <- sorted_target_freq[1:20]\n\n# Create word cloud with top 20 words\nwordcloud(top_target_words, freq = top_target_freq, scale = c(2, 0.4), random.order = FALSE, colors = brewer.pal(8, \"Dark2\"))\n\n\n\n\n\n\nIn this section, you will learn how to perform basic text sensing using appropriate functions of tidytext package.\n\n\nThe code chunk below calculates number of times the word fish appeared in the field product_services.\n\nmc3_nodes %>% \n    mutate(n_fish = str_count(product_services, \"fish\")) \n\n# A tibble: 27,622 × 6\n   id                          country type  revenue_omu product_services n_fish\n   <chr>                       <chr>   <chr>       <dbl> <chr>             <int>\n 1 Jones LLC                   ZH      Comp…  310612303. Automobiles           0\n 2 Coleman, Hall and Lopez     ZH      Comp…  162734684. Passenger cars,…      0\n 3 Aqua Advancements Sashimi … Oceanus Comp…  115004667. Holding firm wh…      0\n 4 Makumba Ltd. Liability Co   Utopor… Comp…   90986413. Car service, ca…      0\n 5 Taylor, Taylor and Farrell  ZH      Comp…   81466667. Fully electric …      0\n 6 Harmon, Edwards and Bates   ZH      Comp…   75070435. Discount superm…      0\n 7 Punjab s Marine conservati… Riodel… Comp…   72167572. Beef, pork, chi…      0\n 8 Assam   Limited Liability … Utopor… Comp…   72162317. Power and Gas s…      0\n 9 Ianira Starfish Sagl Import Rio Is… Comp…   68832979. Light commercia…      0\n10 Moran, Lewis and Jimenez    ZH      Comp…   65592906. Automobiles, tr…      0\n# ℹ 27,612 more rows\n\n\n\n\n\nThe word tokenisation have different meaning in different scientific domains. In text sensing, tokenisation is the process of breaking up a given text into units called tokens. Tokens can be individual words, phrases or even whole sentences. In the process of tokenisation, some characters like punctuation marks may be discarded. The tokens usually become the input for the processes like parsing and text mining.\nIn the code chunk below, unnest_token() of tidytext is used to split text in product_services field into words.\n\ntoken_nodes <- mc3_nodes %>%\n  unnest_tokens(word, \n                product_services)\n\nThe two basic arguments to unnest_tokens() used here are column names. First we have the output column name that will be created as the text is unnested into it (word, in this case), and then the input column that the text comes from (product_services, in this case).\nNow we can visualise the words extracted by using the code chunk below.\n\ntoken_nodes %>%\n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")\n\n\n\n\nThe bar chart reveals that the unique words contains some words that may not be useful to use. For instance “a” and “to”. In the word of text mining we call those words stop words. You want to remove these words from your analysis as they are fillers used to compose a sentence.\n\n\n\nLucky for use, the tidytext package has a function called stop_words that will help us clean up stop words.\nLet’s give this a try next!\n\nstopwords_removed <- token_nodes %>% \n  anti_join(stop_words)\n\nNow we can visualise the words extracted by using the code chunk below.\n\nstopwords_removed %>%\n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")\n\n\n\n\n\n\n\n\n\n\n\n\nid1 <- mc3_edges %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- mc3_edges %>%\n  select(target) %>%\n  rename(id = target)\nmc3_nodes1 <- rbind(id1, id2) %>%\n  distinct() %>%\n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n\n\nmc3_graph <- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\n\nmc3_graph %>%\n  filter(betweenness_centrality >= 100000) %>%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10))+\n  theme_graph()\n\n\n\n\n\n\n\nWith the original graph not clear enough, it is good to add in color and change the layout format of the Network graph, and most importantly, increase the betweenness centrality.\n\nmc3_graph %>%\n  filter(betweenness_centrality >= 1000000) %>%\nggraph(layout = \"kk\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    color = closeness_centrality, alpha = 0.5), show.legend = FALSE) +\n  scale_size_continuous(range=c(1,4)) +  # Add the plot title\n  theme_graph()\n\n\n\n\nBy adding shapes and colors for different variables in the graph, it shows a better visualization of how the network graphs links each entries in the dataset.\n\nmc3_graph %>%\n  filter(betweenness_centrality >= 1000000) %>%\n  ggraph(layout = \"kk\") +\n  geom_edge_link(aes(alpha = 0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    color = type,\n    shape = type),  # Add the shape aesthetic\n    alpha = 0.5) +\n  scale_size_continuous(range = c(1, 4)) +\n  scale_color_manual(values = c(\"Company Contacts\" = \"red\", \"Beneficial Owner\" = \"blue\", \"Company\" = \"green\")) +\n  scale_shape_manual(values = c(\"Company Contacts\" = \"triangle\", \"Beneficial Owner\" = \"square\", \"Company\" = \"circle\")) +  # Add the shape values\n  theme_graph()\n\n\n\n\n\n\n\nBelow network graph labels the nodes with more than 3 edges, which there is only 1, the “Wave Warriors S.A. de C.V. Express”\n\nmc3_graph <- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = as.factor(centrality_closeness())) %>%\n  filter(betweenness_centrality >= 1000000)\n\n         \n# Calculate the degrees of each node\ndegrees <- degree(mc3_graph)\nset.seed (1234)\n\nmc3_graph %>%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = 0.5)) +\n  geom_node_point(aes(size = betweenness_centrality,\n                      color = closeness_centrality,\n                      alpha = 0.5), show.legend = FALSE) +\n  geom_node_text(aes(label = ifelse(degrees > 3, as.character(id), \"\")), size = 3) +  # Add node labels\n  scale_size_continuous(range = c(1, 10)) + \n  theme_graph()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "The code chunk below will be used to install and load the necessary R packages to meet the data preparation, data wrangling, data analysis and visualisation needs.\n\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, tidyverse, lubridate, igraph, stringr, ggplot2, GGally, igraph, ggforce, wordcloud, treemap, gridExtra, reshape2, mice)\n\n\n\nIn the code chunk below, fromJSON() of jsonlite package is used to import mc2_challenge_graph.json into R environment.\n\nMC2 <- fromJSON(\"data/mc2_challenge_graph.json\")\n\nExamine the list object created by using RStudio, especially nodes and links data tables.\n\n\n\n\n\nThe code chunk is used to extract nodes data table from mc2_data list object and save the output in a tibble data frame object called mc2_nodes.\n\nMC2_nodes <- as_tibble(MC2$nodes) %>%\n  select(id, shpcountry, rcvcountry)\n\n\n\n\nThe code chunk is used to extract edgess data table from mc2_data list object and save the output in a tibble data frame object called mc2_edges.\n\nMC2_edges <- as_tibble(MC2$links) %>%\n  mutate(ArrivalDate = ymd(arrivaldate)) %>%\n  mutate(Year = year(ArrivalDate)) %>%\n  select(source, target, ArrivalDate, Year, hscode, valueofgoods_omu, \n         volumeteu, weightkg, valueofgoodsusd) %>% \n  distinct()\n\nlet’s take a closer look at the structure of the MC2_nodes and MC2_edges tibbles\n\nglimpse(MC2_nodes)\n\nRows: 34,576\nColumns: 3\n$ id         <chr> \"AquaDelight Inc and Son's\", \"BaringoAmerica Marine Ges.m.b…\n$ shpcountry <chr> \"Polarinda\", NA, \"Oceanus\", NA, \"Oceanus\", \"Kondanovia\", NA…\n$ rcvcountry <chr> \"Oceanus\", NA, \"Oceanus\", NA, \"Oceanus\", \"Utoporiana\", NA, …\n\nglimpse(MC2_edges)\n\nRows: 5,309,087\nColumns: 9\n$ source           <chr> \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son…\n$ target           <chr> \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica M…\n$ ArrivalDate      <date> 2034-02-12, 2034-03-13, 2028-02-07, 2028-02-23, 2028…\n$ Year             <dbl> 2034, 2034, 2028, 2028, 2028, 2028, 2028, 2028, 2028,…\n$ hscode           <chr> \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"47…\n$ valueofgoods_omu <dbl> 141015, 141015, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ volumeteu        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weightkg         <int> 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, …\n$ valueofgoodsusd  <dbl> NA, NA, NA, NA, NA, NA, 87110, 188140, NA, 221110, 58…\n\n\n\n\n\n\nMC2_edges_aggregated <- MC2_edges %>%\n  filter(hscode == \"306170\" & Year == \"2028\") %>%\n  group_by(source, target, hscode, Year) %>%\n    summarise(weights = n()) %>%\n  filter(source!=target) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n\n\n\n\nInstead of using the nodes data table extracted from mc2_data, we will prepare a new nodes data table by using the source and target fields of mc2_edges_aggregated data table. This is necessary to ensure that the nodes in nodes data tables include all the source and target values.\n\nid1 <- MC2_edges_aggregated %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- MC2_edges_aggregated %>%\n  select(target) %>%\n  rename(id = target)\nMC2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#handling-missing-values",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#handling-missing-values",
    "title": "Take-home Exercise 2",
    "section": "Handling Missing Values",
    "text": "Handling Missing Values\nSince there are way too many missing values, we cannot just omit the whole row, now we just keep the NA so far.\n\n# Replace missing values with NA\nMC2_nodes <- MC2_nodes %>%\n  mutate(across(everything(), ~replace_na(., NA)))\n\n# Replace missing values with NA\nMC2_edges <- MC2_edges %>%\n  mutate(across(everything(), ~replace_na(., NA)))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-cleaning",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-cleaning",
    "title": "Take-home Exercise 2",
    "section": "Data Cleaning",
    "text": "Data Cleaning\n\nAggregation or Summarization\nThe below code groups the MC2_edges data by month based on the arrivaldate, calculates the total weight and total value of goods for each month, and stores the results in the summary_by_month tibble.\n\nweight_by_month <- MC2_edges %>%\n  mutate(month = floor_date(ArrivalDate, \"month\")) %>%\n  group_by(month) %>%\n  summarize(total_weight = sum(`weightkg`))\n\nThe below code joins the MC2_nodes and MC2_edges data based on the company name (id), calculates the total weight and total value of goods for each company, and stores the results in the summary_by_company tibble.\n\n# Calculating totals by company\nsummary_by_company <- MC2_nodes %>%\n  inner_join(MC2_edges, by = c(\"id\" = \"source\")) %>%\n  group_by(id) %>%\n  summarize(total_weight = sum(weightkg),\n            total_value = sum(valueofgoods_omu))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#eda",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#eda",
    "title": "Take-home Exercise 2",
    "section": "EDA",
    "text": "EDA\nThe purpose of our visualizations is to evaluate the reliability of FishEye’s predicted knowledge graph links and identify the most reliable sets for completing the graph, focusing on uncovering patterns related to illegal fishing activities and protecting marine species.\n\nViolin Plot\nBelow is the the violin plot for weight and value grouped by company, the weight graph shows a reversed T, meaning a huge amount of outliers, the value plot shows a bottle gourd shape, meaning a condense in top and bottom range of the data, especially the bottom.\n\nviolinplot_weight <- ggplot(summary_by_company, aes(x = \"\", y = total_weight)) +\n  geom_violin() +\n  labs(x = NULL, y = \"Total Weight\") +\n  theme_minimal()\n\nviolinplot_value <- ggplot(summary_by_company, aes(x = \"\", y = total_value)) +\n  geom_violin() +\n  labs(x = NULL, y = \"Total Value\") +\n  theme_minimal()\n\ngrid.arrange(violinplot_weight, violinplot_value, ncol = 2)\n\n\n\n\n\n\nTime Series graph\nThe total weight in time series graph shows a peak in bit 2032, the a year-span low in 2031.\n\n# Plot the total weight by month\nggplot(weight_by_month, aes(x = month, y = total_weight)) +\n  geom_line() +\n  labs(x = \"Month\", y = \"Total Weight\") +\n  ggtitle(\"Total Weight by Month\")\n\n\n\n\n\n\nScatterplot Matrix\nBelow is a scatter plot of shipping countries and receiving countries, with fake country names, it is hard to demonstrate countries based on continents and real maps.\n\n# Remove rows with missing values\ncleaned_data <- na.omit(MC2_nodes)\n\nscatterplot <- ggplot(cleaned_data, aes(x = shpcountry, y = rcvcountry)) +\n  geom_point(color = \"blue\", alpha = 0.5, size = 2) +\n  theme_minimal() +\n  theme(axis.title.x = element_blank(), axis.title.y = element_blank(),\n        axis.text.x = element_blank(), axis.text.y = element_blank(),\n        axis.ticks.x = element_blank(), axis.ticks.y = element_blank())\n\n# Display the scatterplot\nscatterplot\n\n\n\n\n\n\nWord Cloud\nBelow are the word clouds of the most appeared names of the shipping and receiving countries, it could be a better demo than the scatter plot with marked labels\n\n# Calculate the frequency of occurrence for shpcountry or rcvcountry\ncountry_freq <- table(MC2_nodes$shpcountry)  # Replace shpcountry with rcvcountry if desired\n\n# Create the word cloud\nwordcloud(names(country_freq), freq = country_freq, scale = c(4, 0.5), random.order = FALSE, colors = brewer.pal(8, \"Dark2\"))\n\n\n\n\n\n# Calculate the frequency of occurrence for shpcountry or rcvcountry\ncountry_freq <- table(MC2_nodes$rcvcountry)  # Replace shpcountry with rcvcountry if desired\n\n# Create the word cloud\nwordcloud(names(country_freq), freq = country_freq, scale = c(4, 0.5), random.order = FALSE, colors = brewer.pal(8, \"Dark2\"))\n\n\n\n\n\n\nTreemap\nBelow are the treemap for the most appeared shipping and receiving countries again.\n\n# Calculate the frequency or numerical values for shpcountry or rcvcountry\ncountry_data <- data.frame(\n  category = MC2_nodes$shpcountry,  # Replace shpcountry with rcvcountry if desired\n  value = 1  # Replace with the desired numerical values\n)\n\n# Create the treemap\ntreemap(country_data, index = \"category\", vSize = \"value\", algorithm = \"squarified\",\n        title = \"Treemap of Country Categories\", fontsize.labels = c(12, 8), fontsize.title = 14)\n\n\n\n\n\n# Calculate the frequency or numerical values for shpcountry or rcvcountry\ncountry_data <- data.frame(\n  category = MC2_nodes$rcvcountry,  # Replace shpcountry with rcvcountry if desired\n  value = 1  # Replace with the desired numerical values\n)\n\n# Create the treemap\ntreemap(country_data, index = \"category\", vSize = \"value\", algorithm = \"squarified\",\n        title = \"Treemap of Country Categories\", fontsize.labels = c(12, 8), fontsize.title = 14)\n\n\n\n\n\n\nNetwork Graph\nBelow is the network graph for the shipping and receiving countries, without clear labels, it is hard to interpret the data.\n\nmc2_graph <- tbl_graph(nodes = MC2_nodes_extracted,\n                       edges = MC2_edges_aggregated,\n                       directed = TRUE)\n\nggraph(mc2_graph,\n       layout = \"kk\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes()) +\n  theme_graph()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-imputation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-imputation",
    "title": "Take-home Exercise 2",
    "section": "Data Imputation",
    "text": "Data Imputation\nWith a huge amount of missing value, simply removing the whole row would not be sufficient, thus, I tried the method of imputation.\nTo perform multiple imputation for your dataset, we can use the mice package in R.\n\nInstall and load the mice package:\n\n\nlibrary(mice)\n\n\nCreate an imputation model: Define the variables that you want to impute and specify the predictors for each variable. You can use the mice() function to create the imputation model. Here’s an example:\n\n\n# Create an imputation model\nimp_model <- mice(MC2_edges, method = \"mean\")\n\n\n iter imp variable\n  1   1  valueofgoods_omu  volumeteu  valueofgoodsusd\n  1   2  valueofgoods_omu  volumeteu  valueofgoodsusd\n  1   3  valueofgoods_omu  volumeteu  valueofgoodsusd\n  1   4  valueofgoods_omu  volumeteu  valueofgoodsusd\n  1   5  valueofgoods_omu  volumeteu  valueofgoodsusd\n  2   1  valueofgoods_omu  volumeteu  valueofgoodsusd\n  2   2  valueofgoods_omu  volumeteu  valueofgoodsusd\n  2   3  valueofgoods_omu  volumeteu  valueofgoodsusd\n  2   4  valueofgoods_omu  volumeteu  valueofgoodsusd\n  2   5  valueofgoods_omu  volumeteu  valueofgoodsusd\n  3   1  valueofgoods_omu  volumeteu  valueofgoodsusd\n  3   2  valueofgoods_omu  volumeteu  valueofgoodsusd\n  3   3  valueofgoods_omu  volumeteu  valueofgoodsusd\n  3   4  valueofgoods_omu  volumeteu  valueofgoodsusd\n  3   5  valueofgoods_omu  volumeteu  valueofgoodsusd\n  4   1  valueofgoods_omu  volumeteu  valueofgoodsusd\n  4   2  valueofgoods_omu  volumeteu  valueofgoodsusd\n  4   3  valueofgoods_omu  volumeteu  valueofgoodsusd\n  4   4  valueofgoods_omu  volumeteu  valueofgoodsusd\n  4   5  valueofgoods_omu  volumeteu  valueofgoodsusd\n  5   1  valueofgoods_omu  volumeteu  valueofgoodsusd\n  5   2  valueofgoods_omu  volumeteu  valueofgoodsusd\n  5   3  valueofgoods_omu  volumeteu  valueofgoodsusd\n  5   4  valueofgoods_omu  volumeteu  valueofgoodsusd\n  5   5  valueofgoods_omu  volumeteu  valueofgoodsusd\n\n\n\nPerform the imputation: Use the complete() function to impute the missing values in each dataset. This will create multiple imputed datasets.\n\n\n# Perform multiple imputation\nMC2_edges_imputed <- complete(imp_model)\n\nHere is the result:\n\nglimpse(MC2_edges_imputed)\n\nRows: 5,309,087\nColumns: 9\n$ source           <chr> \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son…\n$ target           <chr> \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica M…\n$ ArrivalDate      <date> 2034-02-12, 2034-03-13, 2028-02-07, 2028-02-23, 2028…\n$ Year             <dbl> 2034, 2034, 2028, 2028, 2028, 2028, 2028, 2028, 2028,…\n$ hscode           <chr> \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"47…\n$ valueofgoods_omu <dbl> 141015, 141015, 1665142, 1665142, 1665142, 1665142, 1…\n$ volumeteu        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weightkg         <int> 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, …\n$ valueofgoodsusd  <dbl> 873608.4, 873608.4, 873608.4, 873608.4, 873608.4, 873…\n\n\nSince the categorical variables are hard to work on a imputation, lets do a random sampling on the nodes dataset.\n\n# Identify missing values in the \"shpcountry\" variable\nmissing_indices <- is.na(MC2_nodes$shpcountry)\n\n# Get the observed categories in the \"shpcountry\" variable\nobserved_categories <- MC2_nodes$shpcountry[!missing_indices]\n\n# Generate random samples for missing values\nimputed_values <- sample(observed_categories, sum(missing_indices), replace = TRUE)\n\n# Replace missing values with imputed values\nMC2_nodes$shpcountry[missing_indices] <- imputed_values\n\nAnd random sampling to impute missing values in the “rcvcountry” variable\n\n# Identify missing values in the \"rcvcountry\" variable\nmissing_indices <- is.na(MC2_nodes$rcvcountry)\n\n# Get the observed categories in the \"rcvcountry\" variable\nobserved_categories <- MC2_nodes$rcvcountry[!missing_indices]\n\n# Generate random samples for missing values\nimputed_values <- sample(observed_categories, sum(missing_indices), replace = TRUE)\n\n# Replace missing values with imputed values\nMC2_nodes$rcvcountry[missing_indices] <- imputed_values\n\nHere is the result:\n\nglimpse(MC2_nodes)\n\nRows: 34,576\nColumns: 3\n$ id         <chr> \"AquaDelight Inc and Son's\", \"BaringoAmerica Marine Ges.m.b…\n$ shpcountry <chr> \"Polarinda\", \"Coralmarica\", \"Oceanus\", \"Marebak\", \"Oceanus\"…\n$ rcvcountry <chr> \"Oceanus\", \"Oceanus\", \"Oceanus\", \"Oceanus\", \"Oceanus\", \"Uto…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-new-eda",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-new-eda",
    "title": "Take-home Exercise 2",
    "section": "The New EDA",
    "text": "The New EDA\n\nTime Series Graph\nHere is the new time series plot on value of the goods with imputed data. Showing peaks in early 2032 and mid 2034.\n\n# Ensure that ArrivalDate is in the right date format\nMC2_edges_imputed$ArrivalDate <- as.Date(MC2_edges_imputed$ArrivalDate)\n\n# Calculate the monthly sum of valueofgoodsusd\nMC2_monthly_sum <- MC2_edges_imputed %>%\n  mutate(Month = floor_date(ArrivalDate, \"month\")) %>%\n  group_by(Month) %>%\n  summarize(total_value = sum(valueofgoodsusd))\n\n# Generate a time-series plot\nggplot(MC2_monthly_sum, aes(x = Month, y = total_value)) +\n  geom_line() +\n  scale_x_date(date_labels = \"%Y-%m\", date_breaks = \"1 year\") +\n  labs(x = \"Month and Year\", y = \"Sum of Value of Goods in USD\", title = \"Time-series Plot of Value of Goods\") +\n  theme_minimal()\n\n\n\n\n\n\nNetwork Graph\nBelow is the new network graph for the shipping and receiving countries, adding labels and shapes make the graph easier to interpret.\n\n# Create an edge list\nMC2_nodes_select <- MC2_nodes %>%\n  select(shpcountry, rcvcountry) %>%\n  as.matrix()\n\n# Create an undirected graph from the edge list\ng <- graph_from_edgelist(MC2_nodes_select, directed = FALSE)\n\n# Simplify the graph to remove multiple edges between nodes\ng <- simplify(g, remove.multiple = TRUE, remove.loops = TRUE)\n\n# Calculate degree for each node\nV(g)$degree <- degree(g)\n\n# Select top N nodes with highest degree\nN <- 20\ntop_nodes <- names(sort(degree(g), decreasing = TRUE))[1:N]\n\n# Create subgraph with only top nodes\ng_sub <- induced_subgraph(g, top_nodes)\n\n# Define colors for the graph based on the community membership\nfc <- cluster_fast_greedy(g_sub)\ncolors <- rainbow(max(membership(fc)))\nV(g_sub)$color <- colors[membership(fc)]\n\n# Plot the subgraph\nplot(g_sub, \n     vertex.size = V(g_sub)$degree/10,\n     vertex.color = V(g_sub)$color,\n     vertex.label = V(g_sub)$name,  # add labels to the vertices\n     vertex.label.cex = 0.7,  # adjust this value to change the label size\n     vertex.frame.color = NA,\n     edge.arrow.size = 0.5,\n     main = paste(\"Network Graph of Top\", N, \"Shipping and Receiving Countries\"))\n\n\n\n\n\n\nScatterplot\nBelow is a scatter plot of ‘valueofgoodsusd’ vs ‘weightkg’ with Log transformation, with it follows on a broad arising line, with a condensed at the middle of the plot, meaning a common frequency of the weight and value of the goods. The outliers to the line, for instance the right bottom corner, might tells an anomaly to the fishing activity\n\n# Randomly sample a subset of the data\nsubset_data <- MC2_edges_imputed %>%\n  sample_frac(0.1)  # adjust this value as needed\n\n# Generate scatterplot with log transformation\nggplot(subset_data, aes(x = weightkg, y = valueofgoodsusd)) +\n  geom_hex(bins = 50) +\n  scale_x_log10() +\n  scale_y_log10() +\n  theme_minimal() +\n  labs(x = \"Weight (kg) [Log Scale]\", y = \"Value of Goods (USD) [Log Scale]\", \n       title = \"Hexbin Plot of Weight vs Value of Goods (Log Scale)\")\n\n\n\n\n\n\nHistogram\nthe number of transactions that took place each year, with no distinct high or lows, meaning a rather smooth change over the years, but a slight decreasing trend might be telling a different story.\n\nggplot(MC2_edges_imputed, aes(x = Year)) +\n  geom_histogram(fill = 'blue', color = 'black', binwidth = 1) +\n  labs(x = \"Year\", y = \"Count\")\n\n\n\n\n\n\nBoxplot\nBelow is the ‘volumeteu’ per year on a boxplot, with all of the plots shaping into a line, meaning the outliers thrives each single year, which tells the story of the big dealers or anomolies on the trails.\n\nMC2_edges_imputed %>%\n  ggplot(aes(x = as.factor(Year), y = volumeteu)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Volume (TEU) per Year\",\n       x = \"Year\",\n       y = \"Volume (TEU)\")\n\n\n\n\n\n\nScatterplot 2\nBelow is the volumeteu vs weightkg colored by Year, with yellow scattered mostly at the left and green mostly too the right, meaning as time passes, the weight and volume tends to decrease, and the lines meaning a distinct product type as the weight and volume comparison is quite fixed with certain goods.\n\nMC2_edges_imputed %>%\n  ggplot(aes(x = log1p(volumeteu), y = log1p(weightkg), color = factor(Year))) +\n    geom_point(alpha = 0.5, size = 2) +\n    scale_color_brewer(palette=\"Dark2\") + # changing color palette\n    scale_x_continuous(name = \"Log Volume (TEU + 1)\") +\n    scale_y_continuous(name = \"Log Weight (kg + 1)\") +\n    theme_minimal() +\n    labs(color = \"Year\", title = \"Log Weight vs Log Volume colored by Year\")"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex04/In-Class_Ex04.html",
    "href": "In-class_Ex/In-Class_Ex04/In-Class_Ex04.html",
    "title": "In-Class Exercise 4",
    "section": "",
    "text": "pacman::p_load(rstatix, gt, patchwork, tidyverse, webshot2, ggstatsplot)\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\nggplot(exam_data,\n       aes(sample=ENGLISH))+\n  stat_qq() +\n  stat_qq_line()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can see that the points deviate significantly from the straight diagonal line. This is a clear indication that the set of data is not normally distributed.\n\n\n\nqq <- ggplot(exam_data,\n       aes(sample=ENGLISH))+\n  stat_qq() +\n  stat_qq_line()\n\n\nsw_t <- exam_data %>%\n  shapiro_test(ENGLISH) %>%\n  gt()\n\n\ntmp <- tempfile(fileext = '.png')\ngtsave(sw_t, tmp)\ntable_png <- png::readPNG(tmp, native = TRUE)\nqq + table_png\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  vlab = \"English scores\"\n)\n\n\n\n\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  type = \"p\",\n  test.value = 60,\n  vlab = \"English scores\"\n)"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html",
    "href": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html",
    "title": "In-Class Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html#the-data",
    "href": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html#the-data",
    "title": "In-Class Exercise 5",
    "section": "The Data",
    "text": "The Data\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\nImporting network data from files\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\nReviewing the imported data\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\nWrangling time\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\nWrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n    summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  ungroup()\n\n\n\nReviewing the revised edges file\nTable below shows the data structure of the reformatted GAStech_edges data frame\nRows: 1,372\nColumns: 4\n$ source  <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  <dbl> 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday <ord> Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  <int> 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html#creating-network-objects-using-tidygraph",
    "href": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html#creating-network-objects-using-tidygraph",
    "title": "In-Class Exercise 5",
    "section": "Creating network objects using tidygraph",
    "text": "Creating network objects using tidygraph\nIn this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\nThe tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\nThe dplyr verbs in tidygraph\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\nUsing tbl_graph() to build tidygraph data model.\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph's network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\nReviewing the output tidygraph's graph object\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# ℹ 48 more rows\n#\n# A tibble: 1,372 × 4\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\nReviewing the output tidygraph's graph object\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of \"Node Data\" and the first three of \"Edge Data\".\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\nChanging the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest \"weight\" first, we could use activate() and then arrange().\nFor example,\n\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,372 × 4\n   from    to Weekday  Weight\n  <int> <int> <ord>     <int>\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# ℹ 1,366 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "In-Class Exercise 5",
    "section": "Plotting Static Network Graphs with ggraph package",
    "text": "Plotting Static Network Graphs with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph's network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\nPlotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\nChanging the default network graph theme\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it's reference guide at least once.\n\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\nChanging the coloring of the plot\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\nWorking with ggraph's layouts\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\nFruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng <- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\nModifying network nodes\nIn this section, you will colour each node by referring to their respective departments.\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\nModifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html#creating-facet-graphs",
    "href": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html#creating-facet-graphs",
    "title": "In-Class Exercise 5",
    "section": "Creating facet graphs",
    "text": "Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\nWorking with facet_edges()\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it's reference guide at least once.\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\nWorking with facet_edges()\nThe code chunk below uses theme() to change the position of the legend.\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\nA framed facet graph\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\nWorking with facet_nodes()\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it's reference guide at least once.\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html#network-metrics-analysis",
    "href": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html#network-metrics-analysis",
    "title": "In-Class Exercise 5",
    "section": "Network Metrics Analysis",
    "text": "Network Metrics Analysis\n\nComputing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User's Guide to Network Analysis in R to gain better understanding of theses network measures.\n\ng <- GAStech_graph %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\nVisualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng <- GAStech_graph %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\nVisualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng <- GAStech_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "href": "In-class_Ex/In-Class_Ex05/In-Class_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "title": "In-Class Exercise 5",
    "section": "Building Interactive Network Graph with visNetwork",
    "text": "Building Interactive Network Graph with visNetwork\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an \"id\" column, and the edge list must have \"from\" and \"to\" columns.\nThe function also plots the labels for the nodes, using the names of the actors from the \"label\" column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\nData preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n\n\nPlotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\nWorking with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\n\nWorking with visual attributes - Nodes\nvisNetwork() looks for a field called \"group\" in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\nWorking with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\nInteractivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n- The argument highlightNearest highlights nearest when clicking a node.\n- The argument nodesIdSelection adds an id node selection creating an HTML select element.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#boxplot-on-revenue",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#boxplot-on-revenue",
    "title": "Take-home Exercise 3",
    "section": "Boxplot on Revenue",
    "text": "Boxplot on Revenue\n\n# Create a boxplot of the revenue distribution\nboxplot(mc3_nodes$revenue_omu, ylab = \"Revenue\", main = \"Boxplot of Company Revenues\")\n\n\n\n\nThe boxplot appears as a reversed “T” shape, the revenue variable exhibits a highly skewed distribution with a long tail towards higher values and outliers, resulting in a reversed “T” shape in the boxplot."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#barchart-on-company-type",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#barchart-on-company-type",
    "title": "Take-home Exercise 3",
    "section": "Barchart on Company Type",
    "text": "Barchart on Company Type\n\ncompany_type_counts <- table(mc3_nodes$type)\npie(company_type_counts, labels = names(company_type_counts),\n    main = \"Company Type Distribution\")\n\n\n\n\nThe bar chart illustrates that approximately 45% of the data consists of beneficial owners, while the remaining portion is divided between companies and company contacts, suggesting a dominant presence of beneficial owners within the dataset."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#initial-network-visualisation-and-analysis",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#initial-network-visualisation-and-analysis",
    "title": "Take-home Exercise 3",
    "section": "Initial Network Visualisation and Analysis",
    "text": "Initial Network Visualisation and Analysis\n\nBuilding network model with tidygraph\n\nid1 <- mc3_edges %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- mc3_edges %>%\n  select(target) %>%\n  rename(id = target)\nmc3_nodes1 <- rbind(id1, id2) %>%\n  distinct() %>%\n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n\n\nmc3_graph <- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#text-sensing-with-tidytext",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#text-sensing-with-tidytext",
    "title": "Take-home Exercise 3",
    "section": "Text Sensing with tidytext",
    "text": "Text Sensing with tidytext\nIn this section, you will learn how to perform basic text sensing using appropriate functions of tidytext package.\n\nSimple word count\nThe code chunk below calculates number of times the word fish appeared in the field product_services.\n\nmc3_nodes %>% \n    mutate(n_fish = str_count(product_services, \"fish\")) \n\n# A tibble: 27,622 × 6\n   id                          country type  revenue_omu product_services n_fish\n   <chr>                       <chr>   <chr>       <dbl> <chr>             <int>\n 1 Jones LLC                   ZH      Comp…  310612303. Automobiles           0\n 2 Coleman, Hall and Lopez     ZH      Comp…  162734684. Passenger cars,…      0\n 3 Aqua Advancements Sashimi … Oceanus Comp…  115004667. Holding firm wh…      0\n 4 Makumba Ltd. Liability Co   Utopor… Comp…   90986413. Car service, ca…      0\n 5 Taylor, Taylor and Farrell  ZH      Comp…   81466667. Fully electric …      0\n 6 Harmon, Edwards and Bates   ZH      Comp…   75070435. Discount superm…      0\n 7 Punjab s Marine conservati… Riodel… Comp…   72167572. Beef, pork, chi…      0\n 8 Assam   Limited Liability … Utopor… Comp…   72162317. Power and Gas s…      0\n 9 Ianira Starfish Sagl Import Rio Is… Comp…   68832979. Light commercia…      0\n10 Moran, Lewis and Jimenez    ZH      Comp…   65592906. Automobiles, tr…      0\n# ℹ 27,612 more rows\n\n\n\n\nTokenisation\nThe word tokenisation have different meaning in different scientific domains. In text sensing, tokenisation is the process of breaking up a given text into units called tokens. Tokens can be individual words, phrases or even whole sentences. In the process of tokenisation, some characters like punctuation marks may be discarded. The tokens usually become the input for the processes like parsing and text mining.\nIn the code chunk below, unnest_token() of tidytext is used to split text in product_services field into words.\n\ntoken_nodes <- mc3_nodes %>%\n  unnest_tokens(word, \n                product_services)\n\nThe two basic arguments to unnest_tokens() used here are column names. First we have the output column name that will be created as the text is unnested into it (word, in this case), and then the input column that the text comes from (product_services, in this case).\nNow we can visualise the words extracted by using the code chunk below.\n\ntoken_nodes %>%\n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")\n\n\n\n\nThe bar chart reveals that the unique words contains some words that may not be useful to use. For instance “a” and “to”. In the word of text mining we call those words stop words. You want to remove these words from your analysis as they are fillers used to compose a sentence.\n\n\nRemoving stopwords\nLucky for use, the tidytext package has a function called stop_words that will help us clean up stop words.\nLet’s give this a try next!\n\nstopwords_removed <- token_nodes %>% \n  anti_join(stop_words)\n\nNow we can visualise the words extracted by using the code chunk below.\n\nstopwords_removed %>%\n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#network-visulization-on-edges",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#network-visulization-on-edges",
    "title": "Take-home Exercise 3",
    "section": "Network Visulization on Edges",
    "text": "Network Visulization on Edges\n\nmc3_graph %>%\n  filter(betweenness_centrality >= 1000) %>%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10))+\n  theme_graph()\n\n\n\n\n\nmc3_graph %>%\n  filter(betweenness_centrality >= 1000) %>%\nggraph(layout = \"kk\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    color = closeness_centrality, alpha = 0.5), show.legend = FALSE) +\n  scale_size_continuous(range=c(1,4))+\n  labs(title = \"Initial Network Visualisation\") +  # Add the plot title\n  theme_graph()\n\n\n\n\n\nmc3_graph %>%\n  filter(betweenness_centrality >= 1000) %>%\n  ggraph(layout = \"kk\") +\n  geom_edge_link(aes(alpha = 0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    color = type,\n    shape = type),  # Add the shape aesthetic\n    alpha = 0.5) +\n  scale_size_continuous(range = c(1, 4)) +\n  scale_color_manual(values = c(\"Company Contacts\" = \"red\", \"Beneficial Owner\" = \"blue\", \"Company\" = \"green\")) +\n  scale_shape_manual(values = c(\"Company Contacts\" = \"triangle\", \"Beneficial Owner\" = \"square\", \"Company\" = \"circle\")) +  # Add the shape values\n  theme_graph()"
  }
]